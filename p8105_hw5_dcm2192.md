p8105_hw5_dcm2192
================
Dylan Morgan
2024-11-15

``` r
library(tidyverse)
library(rvest)
set.seed(1)
```

### Problem 1

### Problem 2

Define function.

``` r
sim_mean_sd <- function(mu, n = 30, sigma = 5) {
  sim_data = tibble(
    x = rnorm(n, mean = mu, sd = sigma)
  )
  sim_data |> 
    t.test() |> 
    broom::tidy() |> 
    summarize(
      mu_hat = estimate, 
      p_value = p.value
    )
}
```

Datasets with mu 0-6.

``` r
sim_results_df <- 
  expand_grid(
    mu = c(0:6),
    iter = 1:5000
  ) |> 
  mutate(
    estimate_df = map(mu, sim_mean_sd)
  ) |> 
  unnest(estimate_df)

head(sim_results_df, 10)
```

    ## # A tibble: 10 × 4
    ##       mu  iter mu_hat p_value
    ##    <int> <int>  <dbl>   <dbl>
    ##  1     0     1  0.412  0.629 
    ##  2     0     2  0.664  0.368 
    ##  3     0     3  0.551  0.534 
    ##  4     0     4  0.567  0.487 
    ##  5     0     5 -1.65   0.0599
    ##  6     0     6  1.19   0.229 
    ##  7     0     7  0.334  0.738 
    ##  8     0     8 -1.19   0.209 
    ##  9     0     9  0.122  0.887 
    ## 10     0    10  0.684  0.472

Plot mu 0-6 where null was rejected.

``` r
sim_results_df |> 
  filter(p_value <= 0.05) |> 
  group_by(mu) |> 
  summarize(n_obs = n()) |> 
  ggplot(aes(x = mu, y = n_obs)) + 
  geom_point() + 
  geom_line() + 
  labs(x = "True value of mu", y = "Number of times null was rejected")
```

![](p8105_hw5_dcm2192_files/figure-gfm/unnamed-chunk-3-1.png)<!-- -->

The relationship between effect size and power is such that the number
of times the null is rejected increases as the true value of mu
increases.

Plot avg estimate of mu-hat and true value of mu.

``` r
sim_results_df |> 
  group_by(mu) |> 
  summarize(avg_mu_hat = mean(mu_hat)) |> 
  ggplot(aes(x = mu, y = avg_mu_hat)) + 
  geom_point() + 
  geom_line() + 
  labs(x = "True value of mu", y = "Average estimate of mu-hat")
```

![](p8105_hw5_dcm2192_files/figure-gfm/unnamed-chunk-4-1.png)<!-- -->

Plot avg estimate of mu-hat (where null was rejected) and true value of
mu.

``` r
sim_results_df |> 
  filter(p_value <= 0.05) |> 
  group_by(mu) |> 
  summarize(avg_mu_hat = mean(mu_hat)) |> 
  ggplot(aes(x = mu, y = avg_mu_hat)) + 
  geom_point() + 
  geom_line() + 
  labs(x = "True value of mu", y = "Average estimate of mu-hat where null was rejected")
```

![](p8105_hw5_dcm2192_files/figure-gfm/unnamed-chunk-5-1.png)<!-- -->

The sample average of mu-hat across tests for which the null is rejected
is approximately equal to the true value of mu because for mu values
greater than 3, the average mu-hat estimate is virtually equal to the
true value of mu. This is not the case for the average mu-hat estimates
for the mu values of 1 and 2, respectively; as the true value of mu
increases from 1, however, the average mu-hat estimate gets closer to
the true value of mu.

### Problem 3

Load raw data.

``` r
homicide_data <- 
  read_csv("./data/homicide-data.csv")
```

    ## Rows: 52179 Columns: 12
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (9): uid, victim_last, victim_first, victim_race, victim_age, victim_sex...
    ## dbl (3): reported_date, lat, lon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

The raw data for `homicide_data` contains 52179 observations of 12
variables. The variables featured in this dataset include the reported
date of the homicide; the name, race, age, and sex of the victim; the
location in which the homicide occurred; and the status of the case
(`disposition`) in terms of whether it remains open with no arrest, or
whether it has been closed with or without an arrest.

Create city_state variable, summarize homicide data by city_state.

``` r
homicide_data <-
  homicide_data |>
  mutate(
    city_state = str_c(city, ", ", state)
  )

homicide_data |>
  group_by(city_state) |>
  summarize(n_obs = n())
```

    ## # A tibble: 51 × 2
    ##    city_state      n_obs
    ##    <chr>           <int>
    ##  1 Albuquerque, NM   378
    ##  2 Atlanta, GA       973
    ##  3 Baltimore, MD    2827
    ##  4 Baton Rouge, LA   424
    ##  5 Birmingham, AL    800
    ##  6 Boston, MA        614
    ##  7 Buffalo, NY       521
    ##  8 Charlotte, NC     687
    ##  9 Chicago, IL      5535
    ## 10 Cincinnati, OH    694
    ## # ℹ 41 more rows

``` r
homicide_data |> 
  filter(disposition != "Closed by arrest") |> 
  group_by(city_state, disposition) |> 
  summarize(n_obs = n())
```

    ## `summarise()` has grouped output by 'city_state'. You can override using the
    ## `.groups` argument.

    ## # A tibble: 95 × 3
    ## # Groups:   city_state [50]
    ##    city_state      disposition           n_obs
    ##    <chr>           <chr>                 <int>
    ##  1 Albuquerque, NM Closed without arrest    52
    ##  2 Albuquerque, NM Open/No arrest           94
    ##  3 Atlanta, GA     Closed without arrest    58
    ##  4 Atlanta, GA     Open/No arrest          315
    ##  5 Baltimore, MD   Closed without arrest   152
    ##  6 Baltimore, MD   Open/No arrest         1673
    ##  7 Baton Rouge, LA Closed without arrest    16
    ##  8 Baton Rouge, LA Open/No arrest          180
    ##  9 Birmingham, AL  Closed without arrest    64
    ## 10 Birmingham, AL  Open/No arrest          283
    ## # ℹ 85 more rows

Baltimore prop test.

``` r
baltimore_prop_test <- 
  prop.test(
  x = (homicide_data |> 
         filter(city_state == "Baltimore, MD", 
                disposition != "Closed by arrest") |> 
         nrow()), 
  n = (homicide_data |> 
         filter(city_state == "Baltimore, MD") |> 
         nrow()), 
  p = 0.5) |> 
  broom::tidy() |> 
  select(estimate, conf.low, conf.high) |> 
  mutate(
    city_state = "Baltimore, MD"
  ) |> 
  relocate(city_state, .before = estimate)

baltimore_prop_test
```

    ## # A tibble: 1 × 4
    ##   city_state    estimate conf.low conf.high
    ##   <chr>            <dbl>    <dbl>     <dbl>
    ## 1 Baltimore, MD    0.646    0.628     0.663

Define prop test function to apply to all city_state values.

``` r
prop_test_func <- function(city_state_param) {
  prop.test(
    x = (homicide_data |> 
           filter(city_state == city_state_param, 
                  disposition != "Closed by arrest") |> 
           nrow()), 
    n = (homicide_data |> 
           filter(city_state == city_state_param) |> 
           nrow()), 
    p = 0.5) |> 
    broom::tidy() |> 
    select(estimate, conf.low, conf.high)
}
```

Map through city_state in homicide data.

``` r
prop_test_results_df <- 
  expand_grid(
    city_state = unique(homicide_data$city_state)
  ) |> 
  mutate(
    prop_est_df = map(city_state, prop_test_func)
  ) |> 
  unnest(prop_est_df)
```

    ## Warning: There was 1 warning in `mutate()`.
    ## ℹ In argument: `prop_est_df = map(city_state, prop_test_func)`.
    ## Caused by warning in `prop.test()`:
    ## ! Chi-squared approximation may be incorrect

``` r
head(prop_test_results_df, 10)
```

    ## # A tibble: 10 × 4
    ##    city_state      estimate conf.low conf.high
    ##    <chr>              <dbl>    <dbl>     <dbl>
    ##  1 Albuquerque, NM    0.386    0.337     0.438
    ##  2 Atlanta, GA        0.383    0.353     0.415
    ##  3 Baltimore, MD      0.646    0.628     0.663
    ##  4 Baton Rouge, LA    0.462    0.414     0.511
    ##  5 Birmingham, AL     0.434    0.399     0.469
    ##  6 Boston, MA         0.505    0.465     0.545
    ##  7 Buffalo, NY        0.612    0.569     0.654
    ##  8 Charlotte, NC      0.300    0.266     0.336
    ##  9 Chicago, IL        0.736    0.724     0.747
    ## 10 Cincinnati, OH     0.445    0.408     0.483
